---
title: "replication of JAE 2016"
output:
  html_document:
    df_print: paged
---

# IZA paper - Empirical example

This notebook accompanies the paper ***Add reference***, and provides a guide on how to implement the approaches introduced in the paper in R.


## Preperation 

### load packages



```{r }
seed=1909
# loading & modifying data
library("readr")         # to read the data
library("dplyr")         # to manipulate data
# charts & tables
library("ggplot2")        # to create charts
library("patchwork")     # to combine charts
library("flextable")     # design tables
library("modelsummary")  # structure tables
# regression & analysis
library("fixest")        # high dimensional FE
library("skimr")         # skim the data
# machine learning
library("policytree")    # policy tree (Athey & Wager, 2021)
library("grf")           # causal forest
library("rsample")      # data splitting 
library("randomForest")             # Traditional Random Forests
library("mlr3")          # learners
library("mlr3learners")          # learners
library("gbm")
library("DoubleML")

```

### Load data & clean data

The next cell loads the example datasets, and preprocesses them to ensure compatibility with the data used in the Jones and Ziebarth (2016). The two datasets are:
* **df_repl**: The full sample dataset, where the relationship between treatment and outcome is not identified (i.e. not causal) 
* **df_sel**: The selected dataset that, according to the identification strategy of Levitt (2008), makes the assumption of treatment unconfoudedness acceptable. See Levitt (2008) and Jones and Ziebarth (2016) for more details.

```{r }
# load data
df_repl<-read_delim("../data/FARS-data-full-sample.txt",delim = "\t")%>%
              filter(year<2004)%>%
              select(-starts_with("imp"))
df_sel<-read_delim("../data/FARS-data-selection-sample.txt",delim = "\t")%>%
              filter(year<2004)%>%
              select(-starts_with("imp"))
# remove rows with missing cases
df_repl<-df_repl[complete.cases(df_repl), ]
df_sel<-df_sel[complete.cases(df_sel), ]
# print number of obs
print(paste('Number of observations in the data:',nrow(df_repl),' (full sample);',nrow(df_sel), ' (selected/causal sample)'))
```


# Analysis

## Double Machine Learning: Or *How to get as much as possible out of your controls*

### Full sample analysis

This section replicates the results of Jones and Ziebarth (2016), henceforth JZ, on the full sample. These results appear in table 1 of the paper. JZ look at the effect that each of the treatment arms (childseat, lap-only belt, or lap and shoulder belt) has on mortality with respect to the null of no protection, which applies to the majority of the sample.

The following list shows the frequency of each treatment arm in this sample.

```{r }
df_repl<-df_repl%>%mutate(T=case_when(
         lapshould==1~"3_lap/should belt	t",
         lapbelt==1~"2_lap only belt",
         childseat==1~"1_childset",
         TRUE~"0_norestrain"),
         Tn=case_when(
         lapshould==1~3,
         lapbelt==1~2,
         childseat==1~1,
         TRUE~0),
         T=factor(T),
         Tbinary=case_when(
         lapshould==1~1,
         lapbelt==1~1,
         childseat==1~1,
         TRUE~0),
         )
        
# df_repl<-df_repl%>%mutate(T=case_when(
#          lapshould==1~"1",
#          lapbelt==1~"1",
#          childseat==1~"1",
#          TRUE~"0"
#          ))
        

         table(df_repl$T)
```

We now create a training and test sample

```{r }
set.seed(seed)
df_repl_split <- initial_split(df_repl, prop = .5)
df_repl_train <- training(df_repl_split)
df_repl_test  <- testing(df_repl_split)
```


JZ, like Levitt (2008), use a linear probability model, and include controls as dummies or fixed effects to investigate the relationship between treatment and mortality. In this sample there is no identification, but we can still investigate whether including control variables in a non-linear way, and thereby allowing for arbitrary interactions between them, affects the results.

To do so, we initialize three models:
1. A ML model to predict the treatment `T` out of the available set of controls `W`
2. A ML model to predict the outcome `y` out of the available set of controls `W`
3. A second stage linear Double Machine Learning Model (DML) to orthogonalize the data using the first-stage models. 


### Binary treatment

The next cell initializes the DML model, fits them twice (the first time without controls.


```{r }
# Create  DML object
dml_data_nocontrols = double_ml_data_from_matrix(y=as.matrix(df_repl_train%>%select(death)),
                                          d=as.matrix(df_repl_train%>%select(Tbinary)), 
                                          X=as.matrix(rep(1,nrow(df_repl_train))))
dml_data_controls = double_ml_data_from_matrix(y=as.matrix(df_repl_train%>%select(death)),
                                          d=as.matrix(df_repl_train%>%select(Tbinary)), 
                                          X=as.matrix(df_repl_train%>%select(highviol,lowviol,splmU55,ruralrd,weekend,
                                                      backright,backleft,row1,age,male,lsimp,rsimp,indrearimp,rearimp,
                                                      indfrimp,frimp,modelyr,year)))
# Learners without controls
lgr::get_logger("mlr3")$set_threshold("warn")
learner=lrn("classif.xgboost")
ml_m = learner$clone()
learner=lrn("regr.xgboost")
ml_g = learner$clone()


# Estimate DMl without controls
obj_dml = DoubleMLPLR$new(dml_data_nocontrols, ml_g=ml_g, ml_m=ml_m)
obj_dml$fit()
print("------------- No controls ------------- ")
print(obj_dml)

# Estimate DMl with controls
obj_dml = DoubleMLPLR$new(dml_data_controls, ml_g=ml_g, ml_m=ml_m)
obj_dml$fit()
print("------------- With controls ------------- ")
print(obj_dml)
```


### Multiarm treatment


```{r ,hide=FALSE}
# Data 
Y=as.matrix(df_repl_train%>%select(death))
D=as.matrix(df_repl_train%>%select(Tn)%>%mutate(Tn=factor(Tn)))
D=as.factor(D)
Xnocontrols=as.matrix(rep(1,nrow(df_repl_train)))
Xdata=df_repl_train%>%select(year,thoulbs_I,age,numcrash)
X=as.matrix(Xdata,nrow=nrow(Xdata))
# Estimate causal foreswt
cfnocontrols <- multi_arm_causal_forest(Xnocontrols, Y, D)
cfcontrols <- multi_arm_causal_forest(X, Y, D)
# Treatment effects


```

```{r , echo=FALSE}
average_treatment_effect(cfnocontrols)
```
```{r , echo=FALSE}

df_repl_train<-df_repl_train%>%mutate(T=case_when(
         lapshould==1~"LapShoulderSeat",
         lapbelt==1~"Lapbelt",
         childseat==1~"Childseat",
         TRUE~"NONE"),
         Tn=factor(T),
         T=factor(T),
         Tbinary=case_when(
         lapshould==1~1,
         lapbelt==1~1,
         childseat==1~1,
         TRUE~0),
         )

D<-factor(df_repl_train$T,levels=c("NONE","Lapbelt","LapShoulderSeat","Childseat"))
```

```{r ,hide=FALSE}
Xdata=df_repl_train%>%mutate(day=ifelse(crashtm=="1_day",1,0),
                             night=ifelse(crashtm=="2_night",1,0),
                             morn=ifelse(crashtm=="3_morn",1,0))%>%
                             select(splmU55,thoulbs_I,numcrash,weekend,lowviol,highviol,ruralrd,day,night,morn,
                                    frimp,suv)
X=as.matrix(Xdata,nrow=nrow(Xdata),ncol=ncol(Xdata))
cfcontrols <- multi_arm_causal_forest(X, Y, D,num.trees=2000)
average_treatment_effect(cfcontrols)
```

## Causal forest


```{r ,hide=FALSE}
# treatment vector
Wmulti<-as.matrix(df_repl%>%
              mutate(W=case_when(
                childseat==1~"Childseat",
                lapbelt==1~"Lapbelt",
                lapshould==1~"LapShoulderSeat",
                TRUE~"NONE"))%>%
               select(W))
Wmulti<-factor(Wmulti,levels=c("NONE","Lapbelt","LapShoulderSeat","Childseat"))

W<-as.matrix(df_repl%>%
              mutate(W=case_when(
                childseat==1~1,
                lapbelt==1~1,
                lapshould==1~1,
                TRUE~0))%>%
               select(W))
# Vector of covariates
X<-as.matrix(df_repl%>%
            select( highviol,lowviol,splmU55,ruralrd,weekend,
          backright,backleft,row1,age,male,lsimp,rsimp,indrearimp,rearimp,
          indfrimp,frimp,modelyr,year))
# Outcome vector
Y<-as.matrix(df_repl%>%
               select(death))
# Estimate CF multiarm
cfmulti <- multi_arm_causal_forest(X, Y, Wmulti)
# Estimate CF single treatment
cf <- causal_forest(X, Y, W)
                
```


### Propensity scores


```{r ,hide=FALSE}

lotdata<-data.frame(what=cfmulti$W.hat)%>%
    pivot_longer(cols=2:4,names_to="type",values_to="value")
ggplot(plotdata)+
  geom_histogram(aes(x = value, y = ..density..),
                  color="white",fill="#3aab54",bins=50)+
  xlim(0,1)+
  theme_minimal()+
    facet_wrap(~type,ncol=1)
                
```


### CATES 


```{r ,hide=FALSE}
cate=predict(cfmulti)
cate["Lapbelt - NONE"]
lotdata<-data.frame(%>%
    pivot_longer(cols=2:4,names_to="type",values_to="value")
ggplot(plotdata)+o
  geom_histogram(aes(x = value, y = ..density..),
                  color="white",fill="#3aab54",bins=50)+
  xlim(0,1)+
  theme_minimal()+
    facet_wrap(~type,ncol=1)
                
```


